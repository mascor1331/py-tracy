{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6e1981b94787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load and parse the job traces from the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgoogle_traces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhello\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mgoogle_traces_RDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'hello'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import parser as p\n",
    "import math_utils\n",
    "\n",
    "# Load and parse the job traces from the dataset\n",
    "google_traces = p.hello()\n",
    "print google_traces_RDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We remove from the traces those that occurred before the beginning of the trace window (timestamp = 0)\n",
    "# and those that occured after the end of the trace window (timestamp = 2^63-1)\n",
    "# and we sort them in ascending order wrt the timestamps\n",
    "filtered_google_traces_RDD = google_traces_RDD.map(lambda elem: (elem[0],(elem[1],elem[2])))\\\n",
    "    .filter(lambda elem: elem[0] != 0 and elem[0] != (2^63 - 1))\\\n",
    "    .sortByKey(1,1)\n",
    "\n",
    "print google_traces_RDD.count() - filtered_google_traces_RDD.count(), \"Traces were removed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# This function takes as input \n",
    "# event_type: int, corresponding to the event type found in the traces\n",
    "# init_time: int (in seconds!), it is the time from which we want to evaluate the model\n",
    "# finish_time: int (in seconds!), it is the time when we want to stop the evaluation\n",
    "# granularity: int (in seconds!), define the level of granularity for plotting the results of the model\n",
    "# E.G. over a window of 200 seconds we may have a granularity of 10 seconds\n",
    "# which means that the derived traces will be clustered, based on the timestamps, in groups following\n",
    "# that granularity\n",
    "# For example assume to start from time = 0 till time = 200\n",
    "# cluster 1: time interval 0-10\n",
    "# cluster 2: time interval 10-20\n",
    "# ...\n",
    "# cluster 20: time interval 180-200\n",
    "\n",
    "def eval_time_window(event_type, init_time, finish_time, granularity):\n",
    "    # First of all we apply another filter to select only the traces that corresponde to the event_type in input\n",
    "    eval_traces_RDD = filtered_google_traces_RDD.filter(lambda elem: elem[1][1] == event_type)\\\n",
    "        .filter(lambda elem: elem[0] >= init_time and elem[0] < finish_time)\\\n",
    "        .map(lambda elem: elem[0])\n",
    "    \n",
    "    # Collect the RDD to get a python list\n",
    "    eval_traces_list = eval_traces_RDD.collect()\n",
    "    evaluated_means_list = []\n",
    "    # This value will always contain the lowest bound for the clusterization based on the granularity\n",
    "    # It's initial values is obviously the init_time\n",
    "    lower_g = init_time\n",
    "    # Define how many clusters we want to create depending on the input granularity\n",
    "    n_cluster = (finish_time-init_time)/granularity\n",
    "    \n",
    "    # We iterate to creare each cluster\n",
    "    for i in range(0,int(n_cluster+1)):\n",
    "        # Define the cluster filtering the derived traces\n",
    "        cluster_traces = [timestamp for timestamp in eval_traces_list if timestamp >= lower_g and timestamp < (lower_g+granularity)]\n",
    "        # We then append to our list a tuple of this format\n",
    "        # (cluster_lower_bound, cluster_upper_bound, mean_time_between_jobs)\n",
    "        evaluated_means_list.append([lower_g, (lower_g+granularity), mu.mean_time_evaluation(sc, cluster_traces)])\n",
    "        # Increase the lower bound to reach the next cluster\n",
    "        lower_g += granularity\n",
    "    \n",
    "    # Remove the NaNs and substitute them with 0s\n",
    "    for elem in evaluated_means_list:\n",
    "        if math.isnan(elem[2]):\n",
    "            elem[2] = 0\n",
    "            \n",
    "    # Prepare dataset for plotting\n",
    "    evaluated_means_RDD = sc.parallelize(evaluated_means_list)\n",
    "    x_axis = evaluated_means_RDD.map(lambda elem: (elem[0]+elem[1])/2).collect()\n",
    "    y_axis = evaluated_means_RDD.map(lambda elem: elem[2]).collect()\n",
    "    \n",
    "    # Plot the graphs\n",
    "    output_notebook()\n",
    "    p = figure(title=\"Mean inter-arrival time\", x_axis_label='Time Window (seconds)', y_axis_label='Mean Time (seconds)')\n",
    "    p.line(x_axis, y_axis, legend=\"Time\", line_width=1.5)\n",
    "\n",
    "    # Show the results\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_time_window(0, 6e+8,21e+8,3e+7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
